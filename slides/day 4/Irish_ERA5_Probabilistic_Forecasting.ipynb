{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ec5d5a",
   "metadata": {},
   "source": [
    "# Probabilistic Weather Forecasting (ERA5 — Dublin)\n",
    "This notebook follows the lecture on **probabilistic forecasting with neural networks**.\n",
    "Using `era5_ireland3_t2m_wind_2024.csv`, we predict **next-hour Dublin 2m temperature** from the **previous 24 hours**.\n",
    "\n",
    "**Plan:**\n",
    "1) Scoring rules (Gaussian NLL, CRPS) + calibration (PIT, reliability).\n",
    "2) Baseline probabilistic model.\n",
    "3) Probabilistic **1D CNN** → (mu, sigma).\n",
    "4) Probabilistic **LSTM** → (mu, sigma).\n",
    "5) Diagnostics & optional quantile head."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858ac04",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe98ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy scikit-learn torch matplotlib\n",
    "import warnings, pathlib\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "CSV_PATH='era5_ireland3_t2m_wind_2024.csv'\n",
    "assert pathlib.Path(CSV_PATH).exists(), 'Place the CSV next to this notebook.'\n",
    "device='cpu'; print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93559626",
   "metadata": {},
   "source": [
    "## 1) Load, split, windows (24→next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ddd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(CSV_PATH, parse_dates=['time']).sort_values('time').reset_index(drop=True)\n",
    "series=df[['Dublin_t2m_degC']].copy()\n",
    "n=len(df); i_tr=int(0.70*n); i_va=int(0.85*n)\n",
    "sc=StandardScaler().fit(series.iloc[:i_tr])\n",
    "x_all=sc.transform(series.values)\n",
    "T=24\n",
    "def make_windows(x,T=24):\n",
    "    Xs,ys=[],[]\n",
    "    for t in range(len(x)-T):\n",
    "        Xs.append(x[t:t+T]); ys.append(x[t+T])\n",
    "    return np.stack(Xs), np.stack(ys)\n",
    "X_all,y_all=make_windows(x_all,T)\n",
    "M=len(X_all); i_tr_w=int(0.70*M); i_va_w=int(0.85*M)\n",
    "Xtr,ytr=X_all[:i_tr_w],y_all[:i_tr_w]\n",
    "Xva,yva=X_all[i_tr_w:i_va_w],y_all[i_tr_w:i_va_w]\n",
    "Xte,yte=X_all[i_va_w:],y_all[i_va_w:]\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X=torch.tensor(X,dtype=torch.float32); self.y=torch.tensor(y,dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i): return self.X[i],self.y[i]\n",
    "tr_dl=DataLoader(SeqDataset(Xtr,ytr),batch_size=128,shuffle=True)\n",
    "va_dl=DataLoader(SeqDataset(Xva,yva),batch_size=256)\n",
    "te_dl=DataLoader(SeqDataset(Xte,yte),batch_size=256)\n",
    "print('Windows:',Xtr.shape,ytr.shape,'|',Xva.shape,yva.shape,'|',Xte.shape,yte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc78360",
   "metadata": {},
   "source": [
    "## 2) Scoring rules & utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gaussian_nll(mu,sigma,y):\n",
    "    var=sigma**2\n",
    "    return 0.5*torch.log(2*torch.pi*var)+0.5*((y-mu)**2)/var\n",
    "def crps_gaussian(mu,sigma,y):\n",
    "    eps=1e-6; sigma=torch.clamp(sigma,min=eps)\n",
    "    z=(y-mu)/sigma\n",
    "    Phi=0.5*(1+torch.erf(z/np.sqrt(2.0)))\n",
    "    phi=torch.exp(-0.5*z**2)/np.sqrt(2*np.pi)\n",
    "    return sigma*( z*(2*Phi-1)+2*phi-1/np.sqrt(np.pi) )\n",
    "def to_celsius(pred_s,true_s,scaler):\n",
    "    return scaler.inverse_transform(pred_s), scaler.inverse_transform(true_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf289ca4",
   "metadata": {},
   "source": [
    "## 3) Baseline probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9244b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mu_tr=torch.tensor(Xtr[:,-1,:]); err= torch.tensor(ytr)-mu_tr\n",
    "    sigma_hat=float(torch.sqrt((err**2).mean()))\n",
    "def eval_baseline(X,y,scaler):\n",
    "    mu=torch.tensor(X[:,-1,:]); sigma=torch.full_like(mu,fill_value=sigma_hat)\n",
    "    nll=gaussian_nll(mu,sigma,torch.tensor(y)).mean().item()\n",
    "    crps=crps_gaussian(mu,sigma,torch.tensor(y)).mean().item()\n",
    "    mu_c,y_c=scaler.inverse_transform(mu.numpy()), scaler.inverse_transform(y)\n",
    "    rmse=float(np.sqrt(((mu_c-y_c)**2).mean()))\n",
    "    return nll,crps,rmse\n",
    "print('sigma_hat (scaled):',round(sigma_hat,4))\n",
    "print('Baseline te metrics:', eval_baseline(Xte,yte,sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838aca1",
   "metadata": {},
   "source": [
    "## 4) Probabilistic 1D CNN (mu, sigma) with Gaussian NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv1d(1,8,3,padding=1)\n",
    "        self.conv2=nn.Conv1d(8,16,3,padding=1)\n",
    "        self.pool=nn.AdaptiveAvgPool1d(1)\n",
    "        self.head=nn.Linear(16,2)\n",
    "        self.softplus=nn.Softplus()\n",
    "    def forward(self,x):\n",
    "        x=x.transpose(1,2)\n",
    "        h=torch.relu(self.conv1(x)); h=torch.relu(self.conv2(h))\n",
    "        h=self.pool(h).squeeze(-1)\n",
    "        out=self.head(h)\n",
    "        mu=out[:,:1]; sigma=self.softplus(out[:,1:])+1e-3\n",
    "        return mu,sigma\n",
    "torch.manual_seed(0)\n",
    "model_cnn=ProbCNN(); opt=torch.optim.Adam(model_cnn.parameters(),lr=3e-3)\n",
    "def eval_nll(model,loader):\n",
    "    model.eval(); tot=0;n=0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in loader:\n",
    "            mu,sig=model(xb)\n",
    "            l=gaussian_nll(mu,sig,yb).mean().item(); tot+=l*len(xb); n+=len(xb)\n",
    "    return tot/n\n",
    "for ep in range(10):\n",
    "    model_cnn.train(); run=0;ntr=0\n",
    "    for xb,yb in tr_dl:\n",
    "        opt.zero_grad(); mu,sig=model_cnn(xb)\n",
    "        loss=gaussian_nll(mu,sig,yb).mean(); loss.backward(); opt.step()\n",
    "        run+=loss.item()*len(xb); ntr+=len(xb)\n",
    "    val=eval_nll(model_cnn,va_dl)\n",
    "    print(f'Epoch {ep+1:02d} | train NLL={run/ntr:.4f} | val NLL={val:.4f}')\n",
    "# Test\n",
    "model_cnn.eval(); P_mu=[];P_sig=[];Y=[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb in te_dl:\n",
    "        mu,sig=model_cnn(xb); P_mu.append(mu.numpy()); P_sig.append(sig.numpy()); Y.append(yb.numpy())\n",
    "P_mu=np.vstack(P_mu); P_sig=np.vstack(P_sig); Y=np.vstack(Y)\n",
    "nll_te=float(gaussian_nll(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "crps_te=float(crps_gaussian(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "mu_c, y_c = sc.inverse_transform(P_mu), sc.inverse_transform(Y)\n",
    "rmse_mu=float(np.sqrt(((mu_c-y_c)**2).mean()))\n",
    "print('CNN te — NLL:',round(nll_te,3),'CRPS:',round(crps_te,3),'RMSE °C:',round(rmse_mu,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3ebfb",
   "metadata": {},
   "source": [
    "## 5) Probabilistic LSTM (mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf235da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbLSTM(nn.Module):\n",
    "    def __init__(self,hidden=32):\n",
    "        super().__init__(); self.lstm=nn.LSTM(1,hidden,batch_first=True); self.head=nn.Linear(hidden,2); self.softplus=nn.Softplus()\n",
    "    def forward(self,x):\n",
    "        o,_=self.lstm(x); h=o[:,-1,:]; out=self.head(h); mu=out[:,:1]; sigma=self.softplus(out[:,1:])+1e-3; return mu,sigma\n",
    "model_lstm=ProbLSTM(); opt=torch.optim.Adam(model_lstm.parameters(),lr=3e-3)\n",
    "for ep in range(10):\n",
    "    model_lstm.train(); run=0;ntr=0\n",
    "    for xb,yb in tr_dl:\n",
    "        opt.zero_grad(); mu,sig=model_lstm(xb); loss=gaussian_nll(mu,sig,yb).mean(); loss.backward(); opt.step()\n",
    "        run+=loss.item()*len(xb); ntr+=len(xb)\n",
    "    # val\n",
    "    model_lstm.eval(); tot=0;n=0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in va_dl:\n",
    "            mu,sig=model_lstm(xb); l=gaussian_nll(mu,sig,yb).mean().item(); tot+=l*len(xb); n+=len(xb)\n",
    "    print(f'Epoch {ep+1:02d} | train NLL={run/ntr:.4f} | val NLL={tot/n:.4f}')\n",
    "# Test\n",
    "model_lstm.eval(); P_mu=[];P_sig=[];Y=[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb in te_dl:\n",
    "        mu,sig=model_lstm(xb); P_mu.append(mu.numpy()); P_sig.append(sig.numpy()); Y.append(yb.numpy())\n",
    "P_mu=np.vstack(P_mu); P_sig=np.vstack(P_sig); Y=np.vstack(Y)\n",
    "nll_te=float(gaussian_nll(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "crps_te=float(crps_gaussian(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "mu_c, y_c = sc.inverse_transform(P_mu), sc.inverse_transform(Y)\n",
    "rmse_mu=float(np.sqrt(((mu_c-y_c)**2).mean()))\n",
    "print('LSTM te — NLL:',round(nll_te,3),'CRPS:',round(crps_te,3),'RMSE °C:',round(rmse_mu,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2def564",
   "metadata": {},
   "source": [
    "## 6) Calibration: PIT histogram & reliability for quantiles (CNN outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f5577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import erf\n",
    "def pit_vals(mu,sigma,y):\n",
    "    eps=1e-6; sigma=np.maximum(sigma,eps)\n",
    "    z=(y-mu)/sigma\n",
    "    return 0.5*(1+erf(z/np.sqrt(2.0)))\n",
    "pit=pit_vals(P_mu[:,0],P_sig[:,0],Y[:,0])\n",
    "plt.figure(figsize=(6,3)); plt.hist(pit,bins=15,edgecolor='k'); plt.title('PIT histogram (CNN)'); plt.xlabel('u'); plt.ylabel('count'); plt.show()\n",
    "from scipy.stats import norm\n",
    "qs=np.linspace(0.1,0.9,9); cov=[]\n",
    "for q in qs:\n",
    "    zq=norm.ppf(q); qhat=P_mu+zq*P_sig; cov.append(float((Y<=qhat).mean()))\n",
    "plt.figure(figsize=(4,4)); plt.plot([0,1],[0,1],'k--'); plt.plot(qs,cov,marker='o'); plt.xlabel('Nominal'); plt.ylabel('Observed'); plt.title('Reliability (CNN)'); plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea287f",
   "metadata": {},
   "source": [
    "## 7) (Optional) Quantile head with pinball loss — starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf2f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the slides for quantile regression motivation; a small example is included here.\n",
    "class TinyCNNBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.conv1=nn.Conv1d(1,8,3,padding=1); self.conv2=nn.Conv1d(8,16,3,padding=1); self.pool=nn.AdaptiveAvgPool1d(1); self.out_dim=16\n",
    "    def forward(self,x): x=x.transpose(1,2); h=torch.relu(self.conv1(x)); h=torch.relu(self.conv2(h)); h=self.pool(h).squeeze(-1); return h\n",
    "class QuantileNet(nn.Module):\n",
    "    def __init__(self, base, quantiles=(0.1,0.5,0.9)):\n",
    "        super().__init__(); self.base=base; self.out=nn.Linear(base.out_dim,len(quantiles)); self.q=torch.tensor(quantiles,dtype=torch.float32).view(1,-1)\n",
    "    def forward(self,x): h=self.base(x); return self.out(h)\n",
    "def pinball_loss(q_pred,y,quantiles=(0.1,0.5,0.9)):\n",
    "    qs=torch.tensor(quantiles,dtype=torch.float32,device=q_pred.device).view(1,-1)\n",
    "    e=y-q_pred; return torch.mean(torch.maximum(qs*e,(qs-1)*e))\n",
    "# Training loop omitted for brevity; see previous notebooks' pattern."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
