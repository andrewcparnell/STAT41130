{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb38fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (50x5 and 2x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.5\u001b[39m*torch.log(\u001b[32m2\u001b[39m*math.pi*sigma**\u001b[32m2\u001b[39m) + \u001b[32m0.5\u001b[39m*((y - mu)**\u001b[32m2\u001b[39m)/(sigma**\u001b[32m2\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1000\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     mu, sigma = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     loss = gaussian_nll(y, mu, sigma).mean()\n\u001b[32m     51\u001b[39m     opt.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mTinyProbNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     34\u001b[39m     h = F.relu(\u001b[38;5;28mself\u001b[39m.h(x))\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     mu, raw_sigma = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m.chunk(\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# ensure positivity; softplus is numerically stable\u001b[39;00m\n\u001b[32m     37\u001b[39m     sigma = F.softplus(raw_sigma) + \u001b[32m1e-6\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (50x5 and 2x2)"
     ]
    }
   ],
   "source": [
    "# Probabilistic NN with one hidden neuron (Gaussian output)\n",
    "# ---------------------------------------------------------\n",
    "# - predicts mean μ(x) and std σ(x)\n",
    "# - trained with Gaussian NLL\n",
    "# - synthetic data has heteroscedastic noise (σ varies with x)\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = \"cpu\"\n",
    "\n",
    "# 1) Make simple synthetic data\n",
    "n = 50\n",
    "# Simulate a x from uniform\n",
    "x = -3 + 6 * torch.rand(n, 1).sort(dim=0).values  # shape (n, 1)\n",
    "#x = torch.linspace(-3, 3, n).unsqueeze(1)\n",
    "true_sigma = 0.1 + 0.5*torch.sigmoid(2*x)         # noise increases with x\n",
    "y = torch.sin(x) + true_sigma * torch.randn_like(x)\n",
    "\n",
    "x, y = x.to(device), y.to(device)\n",
    "\n",
    "# 2) Tiny model: 1 hidden neuron (ReLU) -> 2 outputs (mu, raw_sigma)\n",
    "class TinyProbNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h = nn.Linear(1, 5)      # 1 input -> 5 hidden neurons\n",
    "        self.out = nn.Linear(5, 2)    # outputs: [mu, raw_sigma]\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.h(x))\n",
    "        mu, raw_sigma = self.out(h).chunk(2, dim=1)\n",
    "        # ensure positivity; softplus is numerically stable\n",
    "        sigma = F.softplus(raw_sigma) + 1e-6\n",
    "        return mu, sigma\n",
    "\n",
    "model = TinyProbNN().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "\n",
    "# 3) Training loop with Gaussian NLL\n",
    "def gaussian_nll(y, mu, sigma):\n",
    "    # NLL = 0.5*log(2πσ^2) + (y-μ)^2 / (2σ^2)\n",
    "    return 0.5*torch.log(2*math.pi*sigma**2) + 0.5*((y - mu)**2)/(sigma**2)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    mu, sigma = model(x)\n",
    "    loss = gaussian_nll(y, mu, sigma).mean()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print(f\"epoch {epoch+1:4d} | loss {loss.item():.4f} | \"\n",
    "              f\"μ(0)={model(x[[n//2]])[0].item():.3f}, σ(0)={model(x[[n//2]])[1].item():.3f}\")\n",
    "\n",
    "# 4) Quick sanity check at a few x locations\n",
    "with torch.no_grad():\n",
    "    probe = torch.tensor([[-2.0], [0.0], [2.0]])\n",
    "    mu_hat, sigma_hat = model(probe)\n",
    "    print(\"\\nProbes:\")\n",
    "    for xi, mui, si in zip(probe.flatten(), mu_hat.flatten(), sigma_hat.flatten()):\n",
    "        print(f\"x={xi.item():>4.1f} -> μ={mui.item():+.3f}, σ={si.item():.3f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "# Scatter plot of raw data\n",
    "plt.scatter(x.cpu().numpy(), y.cpu().numpy(), s=10, color='gray', alpha=0.6, label='Raw data')\n",
    "\n",
    "# Predicted mean\n",
    "plt.plot(x.cpu().numpy(), mu.cpu().detach().numpy(), color='blue', label='Predicted μ(x)')\n",
    "\n",
    "# Candlestick: μ(x) ± 2σ(x)\n",
    "mu_np = mu.cpu().detach().numpy().flatten()\n",
    "sigma_np = sigma.cpu().detach().numpy().flatten()\n",
    "\n",
    "level = norm.ppf(0.75) # for a 50% credible interval\n",
    "\n",
    "upper = mu_np + level * sigma_np\n",
    "lower = mu_np - level * sigma_np\n",
    "\n",
    "plt.vlines(x.cpu().numpy().flatten(), lower, upper, color='red', alpha=0.7, linewidth=1, label='μ(x) ± 2σ(x)')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Probabilistic NN Output')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ba9e6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
