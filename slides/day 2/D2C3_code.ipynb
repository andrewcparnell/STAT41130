{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c05a6b2",
   "metadata": {},
   "source": [
    "\n",
    "# Irish Weather ML Mini‑Lab (ERA5: Dublin, Galway, Cork — 2024)\n",
    "\n",
    "This notebook works **entirely offline** from a single CSV file:  \n",
    "`era5_ireland3_t2m_wind_2024.csv`\n",
    "\n",
    "We’ll build three tiny PyTorch models using that dataset:\n",
    "\n",
    "1. **Nowcasting by naive autoregression:** Predict *Dublin 2m temperature* at time *t* from *t−1* (using a small sample).  \n",
    "2. **1D CNN (temporal):** Predict *Dublin 2m temperature* using recent **multivariate** history from the **other variables** (Galway & Cork temps; 10m wind speeds at Dublin, Galway, Cork).  \n",
    "3. **2D CNN (spatio‑temporal):** Predict **(Dublin, Galway, Cork) 2m temperatures** jointly from a short spatio‑temporal window.\n",
    "\n",
    "> Designed to be simple, quick to run on CPU, and easy to modify for teaching.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d568afa3",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9030c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If you need to install packages inside your environment, uncomment as needed.\n",
    "# %pip install pandas numpy scikit-learn torch matplotlib\n",
    "\n",
    "import os, math, random, pathlib, warnings\n",
    "from dataclasses import dataclass\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "CSV_PATH = \"era5_ireland3_t2m_wind_2024.csv\"  # Put this file in the same folder as this notebook\n",
    "assert pathlib.Path(CSV_PATH).exists(), f\"Couldn't find {CSV_PATH}. Place it next to this notebook.\"\n",
    "print('Found:', CSV_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b79e5",
   "metadata": {},
   "source": [
    "## 1) Load & explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ec407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(CSV_PATH, parse_dates=['time'])\n",
    "df = df.sort_values('time').reset_index(drop=True)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a873913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Date coverage:', df['time'].min(), '→', df['time'].max(), f\"({len(df)} rows)\")\n",
    "ax = df.set_index('time')[['Dublin_t2m_degC','Galway_t2m_degC','Cork_t2m_degC']].resample('1D').mean().plot(figsize=(10,3))\n",
    "ax.set_title('Daily mean 2m Temperature (°C): Dublin / Galway / Cork')\n",
    "ax.set_ylabel('°C'); ax.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bdb10",
   "metadata": {},
   "source": [
    "## 2) Train/Validation/Test split (by time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ddf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split: first 70% train, next 15% val, final 15% test (time-ordered)\n",
    "n = len(df)\n",
    "i_tr = int(0.70*n)\n",
    "i_va = int(0.85*n)\n",
    "splits = {'train': (0, i_tr), 'val': (i_tr, i_va), 'test': (i_va, n)}\n",
    "splits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5629f29",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Task A — Predict Dublin temperature from the **previous hour**\n",
    "\n",
    "A minimal baseline:  \n",
    "\\(\n",
    "\\hat{y}_t = a \\cdot y_{t-1} + b\n",
    "\\)\n",
    "\n",
    "We’ll fit a tiny linear layer `nn.Linear(1,1)` on a **small sample** (first 2000 rows) to keep it very fast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd01af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build lag-1 features for Dublin t2m\n",
    "dd = df[['time','Dublin_t2m_degC']].copy()\n",
    "dd['y'] = dd['Dublin_t2m_degC']\n",
    "dd['x_lag1'] = dd['y'].shift(1)\n",
    "dd = dd.dropna().reset_index(drop=True)\n",
    "\n",
    "small = dd.iloc[:2000].copy() if len(dd) > 2000 else dd.copy()  # small sample\n",
    "i_tr, i_va, i_te = int(0.7*len(small)), int(0.85*len(small)), len(small)\n",
    "X = torch.tensor(small['x_lag1'].values, dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(small['y'].values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_tr, y_tr = X[:i_tr], y[:i_tr]\n",
    "X_va, y_va = X[i_tr:i_va], y[i_tr:i_va]\n",
    "X_te, y_te = X[i_va:i_te], y[i_va:i_te]\n",
    "\n",
    "model_A = nn.Linear(1,1)\n",
    "opt = torch.optim.Adam(model_A.parameters(), lr=0.05)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(300):\n",
    "    model_A.train()\n",
    "    opt.zero_grad()\n",
    "    yhat = model_A(X_tr)\n",
    "    loss = loss_fn(yhat, y_tr)\n",
    "    loss.backward(); opt.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        with torch.no_grad():\n",
    "            val = loss_fn(model_A(X_va), y_va).item()\n",
    "        print(f\"Epoch {epoch+1:3d} | train MSE={loss.item():.4f} | val MSE={val:.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_mse = loss_fn(model_A(X_te), y_te).item()\n",
    "    print(\"Test MSE:\", test_mse)\n",
    "\n",
    "# Quick scatter\n",
    "with torch.no_grad():\n",
    "    yh = model_A(X_te).squeeze().numpy()\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(y_te.squeeze().numpy(), yh, s=8, alpha=0.6)\n",
    "plt.plot([y_te.min(), y_te.max()], [y_te.min(), y_te.max()], linestyle='--')\n",
    "plt.title('Task A: True vs Pred (Test)')\n",
    "plt.xlabel('True Dublin t2m (°C)'); plt.ylabel('Pred (°C)'); plt.grid(True); plt.show()\n",
    "\n",
    "print('Fitted a,b:', [p.detach().numpy().ravel().tolist() for p in model_A.parameters()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44db9c",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Task B — **1D CNN** to predict Dublin t2m from **other variables**\n",
    "\n",
    "**Inputs (per time step):**  \n",
    "- Galway_t2m_degC, Cork_t2m_degC  \n",
    "- Dublin_wind_speed10m_ms, Galway_wind_speed10m_ms, Cork_wind_speed10m_ms\n",
    "\n",
    "We build sequences of length `T=24` hours and predict Dublin t2m at the **next hour**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "INPUT_COLS_B = [\n",
    "    'Galway_t2m_degC','Cork_t2m_degC',\n",
    "    'Dublin_wind_speed10m_ms','Galway_wind_speed10m_ms','Cork_wind_speed10m_ms'\n",
    "]\n",
    "TARGET_COL_B = 'Dublin_t2m_degC'\n",
    "T = 24  # sequence length\n",
    "\n",
    "# Time-ordered split\n",
    "i0, i1 = splits['train']\n",
    "j0, j1 = splits['val']\n",
    "k0, k1 = splits['test']\n",
    "\n",
    "train_df = df.iloc[i0:i1].copy()\n",
    "val_df   = df.iloc[j0:j1].copy()\n",
    "test_df  = df.iloc[k0:k1].copy()\n",
    "\n",
    "# Scale features (fit on train only)\n",
    "sc_X = StandardScaler().fit(train_df[INPUT_COLS_B].values)\n",
    "sc_y = StandardScaler().fit(train_df[[TARGET_COL_B]].values)  # scale target helps training\n",
    "\n",
    "def build_sequences(frame):\n",
    "    X_raw = sc_X.transform(frame[INPUT_COLS_B].values)\n",
    "    y_raw = sc_y.transform(frame[[TARGET_COL_B]].values).ravel()\n",
    "    X_seq, y_seq = [], []\n",
    "    for t in range(len(frame) - T - 1):\n",
    "        X_seq.append(X_raw[t:t+T].T)   # shape: (C, T)\n",
    "        y_seq.append(y_raw[t+T])       # predict next hour\n",
    "    X_seq = np.stack(X_seq)            # (N, C, T)\n",
    "    y_seq = np.array(y_seq)           # (N,)\n",
    "    return X_seq, y_seq\n",
    "\n",
    "Xtr, ytr = build_sequences(train_df)\n",
    "Xva, yva = build_sequences(val_df)\n",
    "Xte, yte = build_sequences(test_df)\n",
    "\n",
    "Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
    "Xva_t = torch.tensor(Xva, dtype=torch.float32)\n",
    "Xte_t = torch.tensor(Xte, dtype=torch.float32)\n",
    "ytr_t = torch.tensor(ytr, dtype=torch.float32).unsqueeze(1)\n",
    "yva_t = torch.tensor(yva, dtype=torch.float32).unsqueeze(1)\n",
    "yte_t = torch.tensor(yte, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "class CNN1D_Dublin(nn.Module):\n",
    "    def __init__(self, in_channels: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),   # → (batch, 32, 1)\n",
    "            nn.Flatten(),              # → (batch, 32)\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):  # x: (B, C, T)\n",
    "        return self.net(x)\n",
    "\n",
    "model_B = CNN1D_Dublin(in_channels=Xtr_t.shape[1])\n",
    "optB = torch.optim.Adam(model_B.parameters(), lr=3e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train_simple(model, Xtr, ytr, Xva, yva, epochs=8, batch=128):\n",
    "    tr_loader = DataLoader(list(zip(Xtr, ytr)), batch_size=batch, shuffle=True)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        ls = 0.0\n",
    "        for xb, yb in tr_loader:\n",
    "            optB.zero_grad()\n",
    "            yh = model(xb)\n",
    "            loss = loss_fn(yh, yb)\n",
    "            loss.backward(); optB.step()\n",
    "            ls += loss.item()*len(xb)\n",
    "        with torch.no_grad():\n",
    "            val = loss_fn(model(Xva), yva).item()\n",
    "        print(f\"Epoch {ep+1:02d} | train MSE={ls/len(Xtr):.4f} | val MSE={val:.4f}\")\n",
    "\n",
    "train_simple(model_B, Xtr_t, ytr_t, Xva_t, yva_t, epochs=10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse_te = loss_fn(model_B(Xte_t), yte_t).item()\n",
    "    print('Test MSE (scaled):', mse_te)\n",
    "    # Convert to °C RMSE\n",
    "    import numpy as _np\n",
    "    rmse_degC = float(_np.sqrt(mse_te) * sc_y.scale_[0])\n",
    "    print('Test RMSE (°C):', rmse_degC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e26328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick qualitative check: a short segment\n",
    "with torch.no_grad():\n",
    "    pred_scaled = model_B(Xte_t).squeeze().numpy()\n",
    "pred = sc_y.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "truth = sc_y.inverse_transform(yte_t.numpy()).ravel()\n",
    "\n",
    "nplot = 200\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(truth[:nplot], label='Truth')\n",
    "plt.plot(pred[:nplot], label='Pred')\n",
    "plt.title('Task B: Dublin t2m — 1D CNN (test segment)')\n",
    "plt.ylabel('°C'); plt.xlabel('Time steps'); plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229ae0e2",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Task C — **2D CNN** for joint (Dublin, Galway, Cork) temperatures\n",
    "\n",
    "We encode a **spatio‑temporal patch**:\n",
    "- **Time axis:** last `T=24` hours\n",
    "- **Space axis:** the three cities ordered as `[Dublin, Galway, Cork]`\n",
    "- **Channels:** for each city we include **(t2m, wind10m)** → total 6 channels\n",
    "\n",
    "Tensor shape per sample: **(C=6, T=24, S=3)**, which we pass to a small `Conv2d` by\n",
    "treating **T × S** as a 2D grid.\n",
    "\n",
    "**Target:** 3‑vector of the **next‑hour** temperatures (Dublin, Galway, Cork), in °C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088921d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "CITIES = ['Dublin','Galway','Cork']\n",
    "T = 24\n",
    "# channel order: [Dub_t2m, Dub_ws, Gal_t2m, Gal_ws, Cork_t2m, Cork_ws]\n",
    "INPUT_COLS_C = [\n",
    "    'Dublin_t2m_degC','Dublin_wind_speed10m_ms',\n",
    "    'Galway_t2m_degC','Galway_wind_speed10m_ms',\n",
    "    'Cork_t2m_degC','Cork_wind_speed10m_ms'\n",
    "]\n",
    "TARGET_COLS_C = ['Dublin_t2m_degC','Galway_t2m_degC','Cork_t2m_degC']\n",
    "\n",
    "# Reuse train/val/test from earlier\n",
    "train_df = df.iloc[splits['train'][0]:splits['train'][1]]\n",
    "val_df   = df.iloc[splits['val'][0]:splits['val'][1]]\n",
    "test_df  = df.iloc[splits['test'][0]:splits['test'][1]]\n",
    "\n",
    "sc_XC = StandardScaler().fit(train_df[INPUT_COLS_C].values)\n",
    "sc_yC = StandardScaler().fit(train_df[TARGET_COLS_C].values)\n",
    "\n",
    "def build_spatiotemporal(frame):\n",
    "    Xr = sc_XC.transform(frame[INPUT_COLS_C].values)  # shape (N, 6)\n",
    "    Yr = sc_yC.transform(frame[TARGET_COLS_C].values) # shape (N, 3)\n",
    "    X_seq, Y_seq = [], []\n",
    "    for t in range(len(frame) - T - 1):\n",
    "        patch = Xr[t:t+T]                 # (T, 6)\n",
    "        dub = np.stack([patch[:,0], patch[:,1]], axis=1)  # (T, 2)\n",
    "        gal = np.stack([patch[:,2], patch[:,3]], axis=1)  # (T, 2)\n",
    "        cor = np.stack([patch[:,4], patch[:,5]], axis=1)  # (T, 2)\n",
    "\n",
    "        Xts = np.zeros((6, T, 3), dtype=np.float32)\n",
    "        Xts[0,:,0] = dub[:,0];  Xts[1,:,0] = dub[:,1]\n",
    "        Xts[2,:,1] = gal[:,0];  Xts[3,:,1] = gal[:,1]\n",
    "        Xts[4,:,2] = cor[:,0];  Xts[5,:,2] = cor[:,1]\n",
    "\n",
    "        X_seq.append(Xts)                     # (6, T, 3)\n",
    "        Y_seq.append(Yr[t+T])                 # (3,)\n",
    "    return np.stack(X_seq), np.stack(Y_seq)\n",
    "\n",
    "XtrC, ytrC = build_spatiotemporal(train_df)\n",
    "XvaC, yvaC = build_spatiotemporal(val_df)\n",
    "XteC, yteC = build_spatiotemporal(test_df)\n",
    "\n",
    "XtrC_t = torch.tensor(XtrC, dtype=torch.float32)\n",
    "XvaC_t = torch.tensor(XvaC, dtype=torch.float32)\n",
    "XteC_t = torch.tensor(XteC, dtype=torch.float32)\n",
    "ytrC_t = torch.tensor(ytrC, dtype=torch.float32)\n",
    "yvaC_t = torch.tensor(yvaC, dtype=torch.float32)\n",
    "yteC_t = torch.tensor(yteC, dtype=torch.float32)\n",
    "\n",
    "class CNN2D_TripleCity(nn.Module):\n",
    "    def __init__(self, in_channels=6):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),   # → (B, 32, 1, 1)\n",
    "            nn.Flatten(),                  # → (B, 32)\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3)               # predict 3 temps\n",
    "        )\n",
    "    def forward(self, x):  # x: (B, C=6, T, S=3)\n",
    "        return self.net(x)\n",
    "\n",
    "model_C = CNN2D_TripleCity(in_channels=6)\n",
    "optC = torch.optim.Adam(model_C.parameters(), lr=3e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train_C(model, Xtr, ytr, Xva, yva, epochs=10, batch=128):\n",
    "    tr_loader = DataLoader(list(zip(Xtr, ytr)), batch_size=batch, shuffle=True)\n",
    "    for ep in range(epochs):\n",
    "        model.train(); runloss = 0.0\n",
    "        for xb, yb in tr_loader:\n",
    "            optC.zero_grad()\n",
    "            yh = model(xb)\n",
    "            loss = loss_fn(yh, yb)\n",
    "            loss.backward(); optC.step()\n",
    "            runloss += loss.item()*len(xb)\n",
    "        with torch.no_grad():\n",
    "            val = loss_fn(model(Xva), yva).item()\n",
    "        print(f\"Epoch {ep+1:02d} | train MSE={runloss/len(Xtr):.4f} | val MSE={val:.4f}\")\n",
    "\n",
    "train_C(model_C, XtrC_t, ytrC_t, XvaC_t, yvaC_t, epochs=10)\n",
    "\n",
    "with torch.no_grad():\n",
    "    mse_te = loss_fn(model_C(XteC_t), yteC_t).item()\n",
    "    pred_scaled = model_C(XteC_t).numpy()\n",
    "    truth_scaled = yteC_t.numpy()\n",
    "    pred = sc_yC.inverse_transform(pred_scaled)\n",
    "    truth = sc_yC.inverse_transform(truth_scaled)\n",
    "    rmse_each = np.sqrt(((pred - truth)**2).mean(axis=0))\n",
    "    print('Test RMSE per city (°C):', dict(zip(['Dublin','Galway','Cork'], rmse_each)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visual check for a short segment\n",
    "nplot = 200\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(truth[:nplot,0], label='Dublin true'); plt.plot(pred[:nplot,0], label='Dublin pred')\n",
    "plt.legend(); plt.title('Task C: Dublin t2m — 2D CNN (test segment)'); plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(truth[:nplot,1], label='Galway true'); plt.plot(pred[:nplot,1], label='Galway pred')\n",
    "plt.legend(); plt.title('Task C: Galway t2m — 2D CNN (test segment)'); plt.grid(True); plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(truth[:nplot,2], label='Cork true'); plt.plot(pred[:nplot,2], label='Cork pred')\n",
    "plt.legend(); plt.title('Task C: Cork t2m — 2D CNN (test segment)'); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28987f40",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Notes & Next steps\n",
    "\n",
    "- Try increasing the sequence length `T`, channels, or adding engineered features (sin/cos hour‑of‑day, day‑of‑year).  \n",
    "- Try **teacher forcing** with multi‑step horizons, or switch the heads to predict **24‑hour trajectories**.  \n",
    "- Consider probabilistic heads (mean/variance) with a Gaussian NLL for uncertainty‑aware forecasts.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
