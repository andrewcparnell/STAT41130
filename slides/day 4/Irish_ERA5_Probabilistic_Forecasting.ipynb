{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ec5d5a",
   "metadata": {},
   "source": [
    "# Probabilistic Weather Forecasting (ERA5 — Dublin)\n",
    "This notebook follows the lecture on **probabilistic forecasting with neural networks**.\n",
    "Using `era5_ireland3_t2m_wind_2024.csv`, we predict **next-hour Dublin 2m temperature** from the **previous 24 hours**.\n",
    "\n",
    "**Plan:**\n",
    "1) Scoring rules (Gaussian NLL, CRPS) + calibration (PIT, reliability).\n",
    "2) Baseline probabilistic model.\n",
    "3) Probabilistic **1D CNN** → (mu, sigma).\n",
    "4) Probabilistic **LSTM** → (mu, sigma).\n",
    "5) Diagnostics & optional quantile head."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8858ac04",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe98ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %pip install pandas numpy scikit-learn torch matplotlib\n",
    "import warnings, pathlib\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "CSV_PATH='../../data/era5_ireland3_t2m_wind_2024.csv'\n",
    "assert pathlib.Path(CSV_PATH).exists(), 'Place the CSV next to this notebook.'\n",
    "device='cpu'; print('Device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93559626",
   "metadata": {},
   "source": [
    "## 1) Load, split, windows (24→next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674ddd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows: (6132, 24, 1) (6132, 1) | (1314, 24, 1) (1314, 1) | (1314, 24, 1) (1314, 1)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(CSV_PATH, parse_dates=['time']).sort_values('time').reset_index(drop=True)\n",
    "series=df[['Dublin_t2m_degC']].copy()\n",
    "n=len(df); i_tr=int(0.70*n); i_va=int(0.85*n)\n",
    "sc=StandardScaler().fit(series.iloc[:i_tr])\n",
    "x_all=sc.transform(series.values)\n",
    "T=24\n",
    "def make_windows(x,T=24):\n",
    "    Xs,ys=[],[]\n",
    "    for t in range(len(x)-T):\n",
    "        Xs.append(x[t:t+T]); ys.append(x[t+T])\n",
    "    return np.stack(Xs), np.stack(ys)\n",
    "X_all,y_all=make_windows(x_all,T)\n",
    "M=len(X_all); i_tr_w=int(0.70*M); i_va_w=int(0.85*M)\n",
    "Xtr,ytr=X_all[:i_tr_w],y_all[:i_tr_w]\n",
    "Xva,yva=X_all[i_tr_w:i_va_w],y_all[i_tr_w:i_va_w]\n",
    "Xte,yte=X_all[i_va_w:],y_all[i_va_w:]\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X=torch.tensor(X,dtype=torch.float32); self.y=torch.tensor(y,dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i): return self.X[i],self.y[i]\n",
    "tr_dl=DataLoader(SeqDataset(Xtr,ytr),batch_size=128,shuffle=True)\n",
    "va_dl=DataLoader(SeqDataset(Xva,yva),batch_size=256)\n",
    "te_dl=DataLoader(SeqDataset(Xte,yte),batch_size=256)\n",
    "print('Windows:',Xtr.shape,ytr.shape,'|',Xva.shape,yva.shape,'|',Xte.shape,yte.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc78360",
   "metadata": {},
   "source": [
    "## 2) Scoring rules & utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5069d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def gaussian_nll(mu,sigma,y):\n",
    "    var=sigma**2\n",
    "    return 0.5*torch.log(2*torch.pi*var)+0.5*((y-mu)**2)/var\n",
    "def crps_gaussian(mu,sigma,y):\n",
    "    eps=1e-6; sigma=torch.clamp(sigma,min=eps)\n",
    "    z=(y-mu)/sigma\n",
    "    Phi=0.5*(1+torch.erf(z/np.sqrt(2.0)))\n",
    "    phi=torch.exp(-0.5*z**2)/np.sqrt(2*np.pi)\n",
    "    return sigma*( z*(2*Phi-1)+2*phi-1/np.sqrt(np.pi) )\n",
    "def to_celsius(pred_s,true_s,scaler):\n",
    "    return scaler.inverse_transform(pred_s), scaler.inverse_transform(true_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf289ca4",
   "metadata": {},
   "source": [
    "## 3) Baseline probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9244b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_hat (scaled): 0.1276\n",
      "Baseline te metrics: (-0.8277833050423323, 0.0550745556672476, 0.45098214929494507)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mu_tr=torch.tensor(Xtr[:,-1,:]); err= torch.tensor(ytr)-mu_tr\n",
    "    sigma_hat=float(torch.sqrt((err**2).mean()))\n",
    "def eval_baseline(X,y,scaler):\n",
    "    mu=torch.tensor(X[:,-1,:]); sigma=torch.full_like(mu,fill_value=sigma_hat)\n",
    "    nll=gaussian_nll(mu,sigma,torch.tensor(y)).mean().item()\n",
    "    crps=crps_gaussian(mu,sigma,torch.tensor(y)).mean().item()\n",
    "    mu_c,y_c=scaler.inverse_transform(mu.numpy()), scaler.inverse_transform(y)\n",
    "    rmse=float(np.sqrt(((mu_c-y_c)**2).mean()))\n",
    "    return nll,crps,rmse\n",
    "print('sigma_hat (scaled):',round(sigma_hat,4))\n",
    "print('Baseline te metrics:', eval_baseline(Xte,yte,sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838aca1",
   "metadata": {},
   "source": [
    "## 4) Probabilistic 1D CNN (mu, sigma) with Gaussian NLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa1f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train NLL=1.0570 | val NLL=0.7230\n",
      "Epoch 02 | train NLL=0.7301 | val NLL=0.6828\n",
      "Epoch 03 | train NLL=0.7106 | val NLL=0.6601\n",
      "Epoch 04 | train NLL=0.6895 | val NLL=0.6358\n",
      "Epoch 05 | train NLL=0.6778 | val NLL=0.6237\n",
      "Epoch 06 | train NLL=0.6644 | val NLL=0.6072\n",
      "Epoch 07 | train NLL=0.6462 | val NLL=0.5892\n",
      "Epoch 08 | train NLL=0.6219 | val NLL=0.5591\n",
      "Epoch 09 | train NLL=0.5893 | val NLL=0.5150\n",
      "Epoch 10 | train NLL=0.5360 | val NLL=0.4411\n",
      "CNN te — NLL: 0.667 CRPS: 0.259 RMSE °C: 2.1\n"
     ]
    }
   ],
   "source": [
    "class ProbCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=nn.Conv1d(1,8,3,padding=1)\n",
    "        self.conv2=nn.Conv1d(8,16,3,padding=1)\n",
    "        self.pool=nn.AdaptiveAvgPool1d(1)\n",
    "        self.head=nn.Linear(16,2)\n",
    "        self.softplus=nn.Softplus()\n",
    "    def forward(self,x):\n",
    "        x=x.transpose(1,2)\n",
    "        h=torch.relu(self.conv1(x)); h=torch.relu(self.conv2(h))\n",
    "        h=self.pool(h).squeeze(-1)\n",
    "        out=self.head(h)\n",
    "        mu=out[:,:1]; sigma=self.softplus(out[:,1:])+1e-3\n",
    "        return mu,sigma\n",
    "torch.manual_seed(0)\n",
    "model_cnn=ProbCNN(); opt=torch.optim.Adam(model_cnn.parameters(),lr=3e-3)\n",
    "def eval_nll(model,loader):\n",
    "    model.eval(); tot=0;n=0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in loader:\n",
    "            mu,sig=model(xb)\n",
    "            l=gaussian_nll(mu,sig,yb).mean().item(); tot+=l*len(xb); n+=len(xb)\n",
    "    return tot/n\n",
    "for ep in range(10):\n",
    "    model_cnn.train(); run=0;ntr=0\n",
    "    for xb,yb in tr_dl:\n",
    "        opt.zero_grad(); mu,sig=model_cnn(xb)\n",
    "        loss=gaussian_nll(mu,sig,yb).mean(); loss.backward(); opt.step()\n",
    "        run+=loss.item()*len(xb); ntr+=len(xb)\n",
    "    val=eval_nll(model_cnn,va_dl)\n",
    "    print(f'Epoch {ep+1:02d} | train NLL={run/ntr:.4f} | val NLL={val:.4f}')\n",
    "# Test\n",
    "model_cnn.eval(); P_mu=[];P_sig=[];Y=[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb in te_dl:\n",
    "        mu,sig=model_cnn(xb); P_mu.append(mu.numpy()); P_sig.append(sig.numpy()); Y.append(yb.numpy())\n",
    "P_mu=np.vstack(P_mu); P_sig=np.vstack(P_sig); Y=np.vstack(Y)\n",
    "nll_te=float(gaussian_nll(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "crps_te=float(crps_gaussian(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "mu_c, y_c = sc.inverse_transform(P_mu), sc.inverse_transform(Y)\n",
    "rmse_mu=float(np.sqrt(((mu_c-y_c)**2).mean()))\n",
    "print('CNN te — NLL:',round(nll_te,3),'CRPS:',round(crps_te,3),'RMSE °C:',round(rmse_mu,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3ebfb",
   "metadata": {},
   "source": [
    "## 5) Probabilistic LSTM (mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf235da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train NLL=1.0032 | val NLL=0.3463\n",
      "Epoch 02 | train NLL=-0.3396 | val NLL=-0.9243\n",
      "Epoch 03 | train NLL=-0.8620 | val NLL=-1.0553\n",
      "Epoch 04 | train NLL=-1.0156 | val NLL=-1.0785\n",
      "Epoch 05 | train NLL=-0.9911 | val NLL=-1.1408\n",
      "Epoch 06 | train NLL=-1.0876 | val NLL=-1.1901\n",
      "Epoch 07 | train NLL=-1.0917 | val NLL=-1.1561\n",
      "Epoch 08 | train NLL=-1.0775 | val NLL=-1.1318\n",
      "Epoch 09 | train NLL=-1.0981 | val NLL=-1.1446\n",
      "Epoch 10 | train NLL=-1.0933 | val NLL=-1.1571\n",
      "LSTM te — NLL: -1.136 CRPS: 0.041 RMSE °C: 0.349\n"
     ]
    }
   ],
   "source": [
    "class ProbLSTM(nn.Module):\n",
    "    def __init__(self,hidden=32):\n",
    "        super().__init__(); self.lstm=nn.LSTM(1,hidden,batch_first=True); self.head=nn.Linear(hidden,2); self.softplus=nn.Softplus()\n",
    "    def forward(self,x):\n",
    "        o,_=self.lstm(x); h=o[:,-1,:]; out=self.head(h); mu=out[:,:1]; sigma=self.softplus(out[:,1:])+1e-3; return mu,sigma\n",
    "model_lstm=ProbLSTM(); opt=torch.optim.Adam(model_lstm.parameters(),lr=3e-3)\n",
    "for ep in range(10):\n",
    "    model_lstm.train(); run=0;ntr=0\n",
    "    for xb,yb in tr_dl:\n",
    "        opt.zero_grad(); mu,sig=model_lstm(xb); loss=gaussian_nll(mu,sig,yb).mean(); loss.backward(); opt.step()\n",
    "        run+=loss.item()*len(xb); ntr+=len(xb)\n",
    "    # val\n",
    "    model_lstm.eval(); tot=0;n=0\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in va_dl:\n",
    "            mu,sig=model_lstm(xb); l=gaussian_nll(mu,sig,yb).mean().item(); tot+=l*len(xb); n+=len(xb)\n",
    "    print(f'Epoch {ep+1:02d} | train NLL={run/ntr:.4f} | val NLL={tot/n:.4f}')\n",
    "# Test\n",
    "model_lstm.eval(); P_mu=[];P_sig=[];Y=[]\n",
    "with torch.no_grad():\n",
    "    for xb,yb in te_dl:\n",
    "        mu,sig=model_lstm(xb); P_mu.append(mu.numpy()); P_sig.append(sig.numpy()); Y.append(yb.numpy())\n",
    "P_mu=np.vstack(P_mu); P_sig=np.vstack(P_sig); Y=np.vstack(Y)\n",
    "nll_te=float(gaussian_nll(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "crps_te=float(crps_gaussian(torch.tensor(P_mu),torch.tensor(P_sig),torch.tensor(Y)).mean())\n",
    "mu_c, y_c = sc.inverse_transform(P_mu), sc.inverse_transform(Y)\n",
    "rmse_mu=float(np.sqrt(((mu_c-y_c)**2).mean()))\n",
    "print('LSTM te — NLL:',round(nll_te,3),'CRPS:',round(crps_te,3),'RMSE °C:',round(rmse_mu,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2def564",
   "metadata": {},
   "source": [
    "## 6) Calibration: PIT histogram & reliability for quantiles (CNN outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f5577b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     z=(y-mu)/sigma\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.5\u001b[39m*(\u001b[32m1\u001b[39m+erf(z/np.sqrt(\u001b[32m2.0\u001b[39m)))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m pit=\u001b[43mpit_vals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_mu\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mP_sig\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m plt.figure(figsize=(\u001b[32m6\u001b[39m,\u001b[32m3\u001b[39m)); plt.hist(pit,bins=\u001b[32m15\u001b[39m,edgecolor=\u001b[33m'\u001b[39m\u001b[33mk\u001b[39m\u001b[33m'\u001b[39m); plt.title(\u001b[33m'\u001b[39m\u001b[33mPIT histogram (CNN)\u001b[39m\u001b[33m'\u001b[39m); plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mu\u001b[39m\u001b[33m'\u001b[39m); plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m); plt.show()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m norm\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mpit_vals\u001b[39m\u001b[34m(mu, sigma, y)\u001b[39m\n\u001b[32m      3\u001b[39m eps=\u001b[32m1e-6\u001b[39m; sigma=np.maximum(sigma,eps)\n\u001b[32m      4\u001b[39m z=(y-mu)/sigma\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.5\u001b[39m*(\u001b[32m1\u001b[39m+\u001b[43merf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m/\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "from math import erf\n",
    "def pit_vals(mu,sigma,y):\n",
    "    eps=1e-6; sigma=np.maximum(sigma,eps)\n",
    "    z=(y-mu)/sigma\n",
    "    return 0.5*(1+erf(z/np.sqrt(2.0)))\n",
    "pit=pit_vals(P_mu[:,0],P_sig[:,0],Y[:,0])\n",
    "plt.figure(figsize=(6,3)); plt.hist(pit,bins=15,edgecolor='k'); plt.title('PIT histogram (CNN)'); plt.xlabel('u'); plt.ylabel('count'); plt.show()\n",
    "from scipy.stats import norm\n",
    "qs=np.linspace(0.1,0.9,9); cov=[]\n",
    "for q in qs:\n",
    "    zq=norm.ppf(q); qhat=P_mu+zq*P_sig; cov.append(float((Y<=qhat).mean()))\n",
    "plt.figure(figsize=(4,4)); plt.plot([0,1],[0,1],'k--'); plt.plot(qs,cov,marker='o'); plt.xlabel('Nominal'); plt.ylabel('Observed'); plt.title('Reliability (CNN)'); plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea287f",
   "metadata": {},
   "source": [
    "## 7) (Optional) Quantile head with pinball loss — starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf2f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the slides for quantile regression motivation; a small example is included here.\n",
    "class TinyCNNBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(); self.conv1=nn.Conv1d(1,8,3,padding=1); self.conv2=nn.Conv1d(8,16,3,padding=1); self.pool=nn.AdaptiveAvgPool1d(1); self.out_dim=16\n",
    "    def forward(self,x): x=x.transpose(1,2); h=torch.relu(self.conv1(x)); h=torch.relu(self.conv2(h)); h=self.pool(h).squeeze(-1); return h\n",
    "class QuantileNet(nn.Module):\n",
    "    def __init__(self, base, quantiles=(0.1,0.5,0.9)):\n",
    "        super().__init__(); self.base=base; self.out=nn.Linear(base.out_dim,len(quantiles)); self.q=torch.tensor(quantiles,dtype=torch.float32).view(1,-1)\n",
    "    def forward(self,x): h=self.base(x); return self.out(h)\n",
    "def pinball_loss(q_pred,y,quantiles=(0.1,0.5,0.9)):\n",
    "    qs=torch.tensor(quantiles,dtype=torch.float32,device=q_pred.device).view(1,-1)\n",
    "    e=y-q_pred; return torch.mean(torch.maximum(qs*e,(qs-1)*e))\n",
    "# Training loop omitted for brevity; see previous notebooks' pattern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat41130",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
